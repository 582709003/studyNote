zoo.cfg配置文件的参数解读
    # 客户端和服务端的心跳时间，毫秒
    tickTime=2000
    # leader和follower初始连接能容忍的最多心跳数，超过这个时间就认为主从通信失败
    initLimit=10
    # leader和follower通信时间如果超过syncLimit * tickTime，leader就认为follower死掉，将其从服务器列表中剔除
    syncLimit=5
    # 保存zookeeper中的数据
    dataDir=D:\sjd\softDownload\apache-zookeeper-3.6.0-bin\apache-zookeeper-3.6.0-bin\data
    dataLogDir=D:\sjd\softDownload\apache-zookeeper-3.6.0-bin\apache-zookeeper-3.6.0-bin\log
    # 客户端连接端口
    clientPort=2181

zookeeper的数据模型
    zookeeper的数据节点可以视为数据结构(或者目录)，树中的各节点被视为znode(即zookeeper node)
    ，一个znode可以有多个子节点，zookeeper节点在结构上表现为树状，使用路径path来定位某个znode，
    比如/ns-1/itcast/mysql/schema1/table1,此处ns-1、itcast、mysql、schema1、table1分别是
    根节点，二级节点，三级节点以及四级节点；其中ns-1是itcast的父节点，itcast是ns-1的子节点；itcast
    是mysql的父节点，mysql是itcast的子节点，以此类推；

    *** znode兼具文件和目录两种特点，既像文件一样维护者数据、元信息、时间戳等数据结构，又像目录一样
    可以作为路径标识 的一部分；
    
    那么如何描述一个znode呢？一个znode大体上分为3部分
        节点的数据：即znode data(节点path，节点data)的关系就像map中的键值对的关系
        节点的子节点children
        节点的状态stat：用来描述当前节点的创建，修改记录，包括cZxid、ctime等
    
    节点状态stat的属性
        注意：当有写操作时，如创建，修改，删除，zookeeper会自动开启一个事务，写操作结束时
              会自动提交事务，事务周期内会创建一个事务id
        见图
        czxid:数据节点创建时的事务id
        ctime：数据节点创建时间
        mzxid：数据节点最后一次更新时的事务id
        mtime：数据节点最后一次更新时 的时间
        pzxid：数据节点的子节点最后一次被修改的事务id
        cversion：当前节点的子节点的更改次数
        dataversion：当前节点的数据被更改的次数
        aclversion：当前节点的权限列表被修改的次数
        ephemeralowner：如果当前节点是临时节点，则表示创建该节点的会话的sessionID；如果该节点是
                        持久节点，该属性值为0
        dataLength：数据内容的长度(字节为单位)
        numchildren:当前数据节点的子节点的个数
    
    znode的类型
        节点有两种，分别为临时节点和永久节点，节点的类型在创建时就会被确定，并且不能改变
    
        临时节点：该节点的生命周期依赖于创建他们的会话(客户端连接上zookeeper服务器建立会话)，一旦
                 会话结束，临时节点将被自动删除，当然也可以手动删除；虽然每个临时节点都会绑定到
                 一个客户端会话，但他们对所有的客户端还是可见的，另外，zookeeper的临时节点是不允许有子节点的
    
        持节化节点：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除
    
    zookeeper常用shell命令
        新增节点
            create [-s] [-e] path data   (-s：有序节点  -e：临时节点，默认是持久化节点)
            这样一来，节点就分为了四小类
            持节化节点
            临时节点
            持久化有序节点：此时创建完成后得到的节点名为指定节点名+自增序号
            临时有序节点
    
        更新/修改节点
            1、直接进行更改
                set path value
    
            2、也可基于版本号进行更改，此时类似于乐观锁机制，当你在修改时传入的数据版本号和当前节点的数据版本号不一致时，
                zookeeper会拒绝本次修改
               set path data -v version
    
        删除节点
            delete [-v version] path  ：当前节点如果没有子节点时才可删除
            和更新节点数据一样，也可以传入版本号，当你传入的数据版本号和当前节点的版本号不一致时，就不会执行操作;
    
             要想删除某个节点及其所有后代节点可以使用递归命令：deleteall path
    
        查看节点
            get path  查看数据
            stat path  查看节点属性，没有数据
    
        查看节点的子节点列表
            查看节点列表有ls path 和 ls2 path，后者是前者的增强，不仅可以查看指定路径下的所有节点，
            可以查看当前节点的信息
            注意：ls -s path   取代ls2命令。
    
        监听器
            get [-w] path
                使用get path [watch] 注册的监听器能够在节点内容发生改变的时候，向客户端发出通知，需要注意的是
                zookeeper的触发器是一次性的，触发一次后就会立即失效。
    
            stat [-w] path
               使用此命令注册的监听器能够在节点状态发生改变的时候向客户端发出通知
    
            ls [-s] [-w] path
                 使用此命令注册的监听器能够在节点的子节点的数量发生改变的时候向客户端发出通知
    
        zookeeper的acl权限控制
            zookeeper类似于文件系统，client可以创建节点，更新节点，删除节点，那么如何做到节点的权限控制呢
            zookeeper的access control list 访问控制列表可以做到这一点
    
            aclq权限控制，使用scheme:id:pemission来标识，主要涵盖3个方面：
            权限模式(scheme)：授权的策略
            授权对象(id):授权的对象
            权限(permission):授予的权限
    
            其特性如下
            1、zookeeper的权限控制是基于每个节点的，需要对每个节点设置权限
            2、每个节点支持设置多种权限控制方案和多个权限
            3、子节点不会继承父节点的权限，如果客户端无权访问某个节点，但是是有可能成功访问它的子节点的
    
            例如：setAcl /hadoop ip:192.168.1.4:crwda //将节点/hadoop的权限设置为只有ip：192.168.1.4的客户端才能对节点
                    进行增、删、改、查、管理的权限
    
            授权模式
                方案     描述
                world   只有一个用户:anyone，代表登录zookeeper的所有人(默认)
                ip      对客户端使用的IP地址进行认证
                auth    使用已添加认证的用户认证
                digest  使用用户名:密码方式认证     密码必须是以密文的形式提供的
    
            授予的权限
                create、delete、read、writer、admin也就是增删改查管理权限，这五种权限简写为cdrwa；
                注意：这五中权限中，delete是指对子节点(仅仅是下一级节点)的删除权限，其他四种权限是指对当前自身节点的操作权限
    
                权限      acl简写           描述
                create  c           可以创建子节点
                delete  d           可以删除子节点(仅仅是下一级)
                read    r           可以读取节点数据以及显示子节点列表
                write   w           可以设置节点数据
                admin   a           可以设置节点访问控制列表权限
    
            授权相关命令
                命令      使用方式                    描述
                getAcl      getAcl path             读取acl权限
                setAcl      setAcl path acl         设置acl权限
                addauth     addauth scheme auth     添加认证用户
    
            world授权模式
                setAcl path world:anyone:acl
    
            ip授权模式
                setAcl path ip:<ip地址>:<acl>
    
            auth授权模式
                命令
                    先添加授权用户：addauth digest <username>:<password>
                    设置权限：setAcl <path> auth:<username>:<acl>
    
            digest授权模式
                和auth模式不同点
                    1、不用先添加用户
                    2、需要先计算一个密文
                命令
                    setAcl <path> digest:<username>:<password>:<acl>
                    这里的密码是经过sha-1以及base64处理过的密文，在shell中可以通过以下命令计算
                    echo -n <username>:<password> | openssl dgst -binary -sha1 | openssl base64
    
                    先来计算一个密文
    
            多种授权模式
                同一个节点可以同时使用多种模式授权
                 setAcl /node4 ip:192.168.1.4:crdwa,auth:sjd:crdwa,.....
    
            acl超级管理员
                见图
    
    zookeeper javaApi
        客户端应该遵循以步骤，与zookeeper服务器进行清晰和干净的交互
            1、连接到zookeeper服务器，zookeeper服务器为客户端分配会话id
            2、客户端定期像服务器发送心跳，否则zookeeper服务器会将当前的会话id过期，客户端需要重新连接
            3、只要会话id处于活跃状态，就可以获取/设置节点
            4、所有任务完成之后，断开与zookeeper服务器的连接，如果客户端长时间不活动，则zookeeper服务器将自动断开客户端
    
        创建节点
           1、同步方式创建节点
              zookeeper.create("/create/node1","node1".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT);
    
           2.同步方式创建节点2，获取节点状态信息
               Stat stat = new Stat();
               String s = zookeeper.create("/create/node4", "node3".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT,stat);
               System.out.println(stat);
    
                //3、异步创建
                zookeeper.create("/create/node7", "node7".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT,
                                    new AsyncCallback.StringCallback(){
                                        @Override
                                       public void processResult(int rc, String path, Object ctx, String name){
                                            System.out.println(rc);
                                            System.out.println(path);
                                            System.out.println(ctx);
                                            System.out.println(name);
                                        }
                                    },"i am context");
                System.out.println("我直接过来了！");
                Thread.sleep(2000);
        更新节点
            //更新节点
                //1、同步更新,版本号取-1代表版本号不参与更新
                Stat stat = zookeeper.setData("/create/node1", "node11".getBytes(), -1);
                System.out.println(stat.getVersion());
    
                //2、异步方法
                zookeeper.setData("/create/node1", "node11".getBytes(), -1, new AsyncCallback.StatCallback() {
                            @Override
                            public void processResult(int rc, String path, Object ctx, Stat stat) {
                                System.out.println(rc);
                                            System.out.println(path);
                                            System.out.println(ctx);
                                            System.out.println(stat);
                            }
                        },"hello");


    zookeeper事件监听机制
        watcher概念
            zookeeper提供了数据的发布订阅功能，多个订阅者可以同时监听某一个特定主题对象，当该主题对象的自身状态发生变化时
            (例如节点改变、节点下的子节点列表改变等)，会实时的、主动的通知所有订阅者
    
            zookeeper采用了watcher机制实现数据的发布/订阅功能，该机制在该被订阅的对象发生变化时会异步的通知客户端，因此
            客户端不必在watcher注册后轮询阻塞，从而减轻了客户端的压力
    
            watcher机制实际上与观察者模式类似，也可看作是一种观察者模式在分布式长江下的实现方式
    
        watcher架构
            watcher实现由三个部分组成
                1、zookeeper服务端
                2、zookeeper客户端
                3、客户端的zkwatcherManager对象
    
                客户端首先将watcher注册到服务器，同时将watcher对象保存到客户端的watch管理器中，当zk服务器监听的数据状态发生改变
                时，服务端主动通知客户端，接着客户端的watch管理器会触发相关watch来回调相应的处理逻辑，从而完成整体的数据发布/订阅
                流程
    
            watch特性
                1、一次性：watcher是一次性的，一旦被触发就会移除，再次使用时需要重新注册
                2、客户端顺序回调：watcher回调时顺序串行化执行的(譬如：一个节点注册了同一个事件的多个监听器对象，这时多个监听器对象回调时串行化执行)，
                                只有回调后客户端才能看到最新的数据状态。一个watcher回调逻辑不应该太多，以免影响别的watcher执行
                3、轻量级：watchEvent是最小的通信单元，结构上只包含通知状态、事件类型和节点路径，并不会告诉数据节点变化前后的具体内容
                4、时效性：watcher只有在当前session彻底失效时才会无效，若在session有效期内快速重连成功，则watcher依然存在，
                          仍可接收到通知
    
            watcher通知状态(keeperState)
                当事件类型为NONE时，也就是数据节点还未发生变化，可以捕获连接状态
                keeperState是客户端与服务器端连接状态发生变化时对应的通知类型，其路径是Watcher.Event.keeperState
                是一个枚举类，枚举属性如下：
                 Disconnected：断开连接时
                                (自己的理解，客户端连接成功后会有一个心跳包请求服务器，请求时还带着一个类似于cookey的东西，
                                 请求不到时，客户端触发监听机制，断开连接)
                SyncConnected:正常连接时
                AuthFailed：身份认证失败时   ：当更新的节点有用户权限限制时，此时如果当前连接没有添加此用户时(添加认证用户后，就会以当前用户去请求zookeeper)
                                            ，此时再去设置此节点就会出现这个状态
                ConnectedReadOnly,
                SaslAuthenticated,
                Expired：会话session失效时
                        注意：ZooKeeper zookeeper = new ZooKeeper(connStr, 5000,watcher);
                            这里有一个session超时时间，如果连接成功后，服务器会对当前连接创建一个会话，
                            此时如果连接断掉了，如果在超时时间内重连成功的话，之前的session正常使用；但是如果超过超时时间
                            重连成功的话之前的session就失效了(自己的理解：客户端带着一个类似于cookey的东西取服务器找session，session超时后，被删除
                                                            所以session没找到，就是session过期)
                Closed;
    
            Watcher事件类型(EventType)
                EventType事件类型是数据节点发生变化时对应的通知类型，EventType变化时keeperState永远处于SyncConnected
                通知的状态下；当keeperState发生变化时，EventType永远处于NONE，其路径为是Watcher.Event.EventType
                也是枚举类，属性如下
                    None(-1)：无
                    NodeCreated(1)：watcher监听的数据节点被创建时
                    NodeDeleted(2)：watcher监听的数据节点被删除时
                    NodeDataChanged(3)：watcher监听的数据节点内容发生变更时(无论内容数据是否变化)
                    NodeChildrenChanged(4)：watcher监听的数据节点的子节点列表发生变化时
                    DataWatchRemoved(5),
                    ChildWatchRemoved(6),
                    PersistentWatchRemoved(7);
                注意：客户端接收到的相关事件通知中只包含状态以及类型信息，不包括节点变化前后的具体内容
    
            捕获相应的事件
                1、zookeeper连接对象创建时第三个参数就是watcher对象，这时就是注册监视器，用来监视连接状态
                2、使用getData,exists,getChildren等javaapi进行监听某个节点的变化
    
                注册方式                      created         childrenChanged         changed         deleted
                zk.exists(path,watcher)       可监控                                   可监控           可监控
                zk.getData (path,watcher)                                             可监控            可监控
                zk.getChildren(path,watcher)                        可监控
    
            watcher机制exists
                1、参数2：是否使用zk连接对象中的监视器
                exists(path,boolean)
    
                2、自定义监视器
                exists(path,watcher)
    
                其他监视器不做介绍
    
    zookeeper配置中心案例
        场景：数据库的用户名和密码信息放在了一个配置文件中，应用读取该配置文件，配置文件信息放入缓存。
        若数据库的用户名和密码改变的时候，还需要重新加载缓存，比较麻烦，通过zookeeper可以轻松完成，当数据库发生变化
        的时候自动完成缓存同步
    
        设计思路
            1、连接zookeeper服务器
            2、读取zookeeper中的配置信息，注册watcher监听器，存入本地变量
            3、当zookeeper中的配置信息发生变化时，通过watcher回调方法捕获数据变化事件
            4、重新获取配置信息
        注意：当捕获到节点数据变化事件时，需要重新获得一个客户端与服务器的连接，然后再使用这个连接去重新获取新的配置信息
    
    生成分布式唯一id
        设计思路
            1、连接zk服务器
            2、指定路径生成临时有序节点
            3、取路径名称中的序列号，这就是分布式环境下的唯一id
    
            package com.example2021.springboot.zookeeper;/**
             * @projectname springboot
             * @author Administrator
             * @create 2021/5/12
             */
    
            import org.apache.zookeeper.*;
    
            import java.util.concurrent.CountDownLatch;
    
            /**
             * @Auther sunjid
             * @Date 2021/5/12
             * @Describtion 生成分布式唯一id
             **/
            public class ZkId implements Watcher {
                String connStr = "192.168.195.1:2181";
                CountDownLatch countDown = new CountDownLatch(1);
                ZooKeeper zookeeper;
                @Override
                public void process(WatchedEvent event) {
                    if (event.getType() !=Event.EventType.None) {
                        if(event.getType()==Event.EventType.NodeCreated){
                            System.out.println("listen:节点创建");
                        }else if(event.getType()==Event.EventType.NodeChildrenChanged){
                            System.out.println("listen:子节点修改");
                        }else if(event.getType()==Event.EventType.NodeDataChanged){
    
                        }
                    }else {
                        if (event.getState() == Event.KeeperState.SyncConnected) {
                            countDown.countDown();
                            System.out.println("连接创建成功！");
                        }else if (event.getState() == Event.KeeperState.Disconnected) {
                            //countDown.countDown();
                            System.out.println("断开连接！");
                        }else if (event.getState() == Event.KeeperState.Expired) {
                            //countDown.countDown();
                            System.out.println("连接超时！");
                        }else if (event.getState() == Event.KeeperState.AuthFailed) {
                            //countDown.countDown();
                            System.out.println("认证失败！");
                        }
                    }
                }
    
                public ZkId(){
                    try {
                        //打开连接对象
                        zookeeper = new ZooKeeper(connStr, 5000,this );
                        countDown.await();
                    }catch (Exception e){
                        e.printStackTrace();
                    }
                }
    
                public String getClobalUid(){
                    String path = "";
                    try {
                        path = zookeeper.create("/uid", new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);
                    }catch (Exception e){
                        e.printStackTrace();
                    }
                    return path.substring(4);
                }


                public static void main(String[] args) {
                    Watcher watcher = new ZkId();
                    for (int i = 0; i < 5; i++) {
                        String clobalUid = ((ZkId) watcher).getClobalUid();
                        System.out.println(clobalUid);
                    }
    
                }
            }
    
    分布式锁
        设计思路
            1、每个客户端往/locks下创建临时有序节点/locks/lock_，创建成功后/locks会有每个客户端对应的节点，
            如/locks/lock_000000001
            2、每个客户端取得/locks下的子节点，并进行排序，判断排在最前面的是否为自己，如果自己在锁节点在第一位，代表获取
                锁成功
            3、如果自己的锁节点不在第一位，则监听自己前一位的锁节点，例如，自己的锁节点lock_000000002,那么监听lock_000000001
            4、当前一位锁节点lock_000000001对应的客户端执行完成，释放了锁，将会触发监听客户端lock_000000002的逻辑
            5、监听客户端重新执行第二部逻辑，判断自己是否获得了锁
    
            package com.example2021.springboot.zookeeper;/**
             * @projectname springboot
             * @author Administrator
             * @create 2021/5/12
             */
    
            import org.apache.zookeeper.*;
            import org.apache.zookeeper.data.Stat;
    
            import java.util.Collections;
            import java.util.List;
            import java.util.concurrent.CountDownLatch;
    
            /**
             * @Auther sunjid
             * @Date 2021/5/12
             * @Describtion zk实现的分布式锁
             **/
            public class MyZkLock {
                String connStr = "192.168.195.1:2181";
                CountDownLatch countDown = new CountDownLatch(1);
                ZooKeeper zookeeper;
                private static final String LOCK_ROOT_PATH = "/Locks";
                private static final String LOCK_NODE_NAME = "/Lock_";
                private String lockPath;
                Watcher watcher=new Watcher() {
                    @Override
                    public void process(WatchedEvent event) {
                        if (event.getType() !=Event.EventType.None) {
                            if(event.getType()==Event.EventType.NodeCreated){
                                System.out.println("listen:节点创建");
                            }else if(event.getType()==Event.EventType.NodeChildrenChanged){
                                System.out.println("listen:子节点修改");
                            }else if(event.getType()==Event.EventType.NodeDataChanged){
    
                            }else if(event.getType()==Event.EventType.NodeDeleted){
                                synchronized (this){
                                    notifyAll();
                                }
                            }
                        }else {
                            if (event.getState() == Event.KeeperState.SyncConnected) {
                                countDown.countDown();
                                System.out.println("连接创建成功！");
                            }else if (event.getState() == Event.KeeperState.Disconnected) {
                                //countDown.countDown();
                                System.out.println("断开连接！");
                            }else if (event.getState() == Event.KeeperState.Expired) {
                                //countDown.countDown();
                                System.out.println("连接超时！");
                            }else if (event.getState() == Event.KeeperState.AuthFailed) {
                                //countDown.countDown();
                                System.out.println("认证失败！");
                            }
                        }
                    }
                };
    
                public MyZkLock(){
                    try {
                        //打开连接对象
                        zookeeper = new ZooKeeper(connStr, 5000,watcher );
                        countDown.await();
                    }catch (Exception e){
                        e.printStackTrace();
                    }
                }



                //获取锁
                public void acquireLock() throws Exception{
                    createLock();
    
                    attemptLock();
                }
    
                //创建锁节点（临时有序节点）
                public void createLock() throws Exception{
                    //判断/locks是否存在，不存在创建
                    Stat exists = zookeeper.exists(LOCK_ROOT_PATH, false);
                    if(exists == null){
                        zookeeper.create(LOCK_ROOT_PATH,new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
                    }
                    //创建临时有序节点
                    lockPath = zookeeper.create(LOCK_ROOT_PATH + LOCK_NODE_NAME, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);
                    System.out.println("临时有序节点创建成功！");
    
                }
    
                //尝试获取锁
                public void attemptLock() throws Exception{
                    //获取locks下的所有子节点
                    List<String> children = zookeeper.getChildren(LOCK_ROOT_PATH, false);
                    System.out.println(lockPath + "------------");
                    //对子节点进行排序
                    Collections.sort(children);
                    //获取当前节点在list里的索引，也就是排序
                    int index = children.indexOf(lockPath.substring(LOCK_ROOT_PATH.length() + 1));
                    if(index == 0){
                        System.out.println("获取锁成功");
                    }else{
                        System.out.println(index);
                        //前面还有节点
                        String path = children.get(index - 1);
                        Stat exists = zookeeper.exists(LOCK_NODE_NAME + "/" + path, watcher);
                        if(exists == null){
                            attemptLock();
                        }else{
                            //阻塞等待
                            synchronized (watcher){
                                watcher.wait();
                            }
                            attemptLock();
                        }


                    }
    
                }
    
                //释放锁
                public void rleaseLock() throws Exception{
                    zookeeper.delete(this.lockPath,-1);
                    zookeeper.close();
                    System.out.println("锁已释放");
                }
    
                public static void main(String[] args) throws Exception {
                    TicketSell ticketSell = new TicketSell();
                    for (int i = 0; i < 10; i++) {
                        ticketSell.sellTicketWithLock();
    
                    }
                }
    
            }

zookeeper集群搭建
    见视频吧，不太好写

一致性协议:zab协议
    zab协议的全称时zookeeper atomic broadcast(zookeeper 原子广播)，zookeeper是通过zab协议来保证分布式事务的最终一致性的
    基于zab协议，zookeeper集群中的角色只要有以下三类
        角色                                                      描述
        领导者                                     领导者负责进行投票的发起和决议，更新系统状态

                跟随者                         follower用于接收客户请求并向客户端返回结果，在选主过程中参与投票
        学习者
                观察者                         observer可以接收客户端连接，将写请求转发给leader节点，但observer不参与投票，
                                                只同步leader的状态，observer的目的是为了扩展系统，提高读取速度
    
        客户端                                     请求发起方
    
    读请求
        每个集群中的zk服务器都可以处理读请求
    
    zab广播模式工作原理，通过类似两阶段提交协议的方式解决数据一致性
        写操作，即便写请求是发送到跟随者，也会转发到leader
        1、leader从客户端收到一个写请求
        2、leader生成一个新的事务并为这个事务生成一个唯一的zxid
        3、leader将这个事务提议(包含这个事务id以及此次写请求的数据)发送给所有的follows节点
        4、follower节点将收到的事务请求加入到历史队列中，并发送ack给leader
        5、当leader收到大多数follower(半数以上节点)的ack消息，leader会发送commit请求
        6、当follower收到commit请求时，从历史队列中将事务请求commit
    
    zookeeper的leader选举
        服务器状态
            looking：寻找leader状态。当服务器处于该状态时，他会认为当前集群中没有leader，因此需要进入					 leader
           选举状态
            leading：领导者状态。表明当前服务器的角色是leader
            following：领导者状态。表明当前服务器的角色是follower
            observing：领导者状态。表明当前服务器的角色时observer
    
        服务器启动时期的leader选举
            在集群初始化阶段，当有一台服务器server1启动时，其无法单独完成leader选举，当第二台服务器server2启动时，此时两台
            机器可以相互通信，每台机器都试图找到leader，于是进入leader选举状态，选举过程如下：
            1、每个server发出一个投票，由于是初始情况，server1和server2都会选举自己为leader，每次投票会包含所选举的服务器的myid
            (服务器ID)和zxid(服务器存放最新的数据version。值越大说明数据越新，在选举算法中数据越新权重越大)，使用(myid，zxid)来表示，
            此时server1的投票为(1,0),server2的投票为(2,0),然后各自将自己的投票发给集群中其他机器
            2、集群中的每台服务器接收来自集群中其他各个服务器的投票
            3、处理投票，针对每一个投票，服务器都需要将别人的投票和自己的投票进行pk，pk规则如下：
                优先检查zxid，zxid比较大的服务器优先作为leader
                如果zxid相同，那么比较myid，myid较大的服务器作为leader服务器
                对于server1而言，他的投票是(1,0),接收到server2的投票为(2,0),他首先会比较两者的zxid，均			  为0，再比较myid，此时server2的myid较大，于是server1就更新了自己的投票为(2,0)；然后重新				投票，对于server2而言，其无需更新自己的投票，只要 将上次的投票信息再次向集群中发出即可；
            4、统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有超过半数的机器接收相同的投票信息，			 对于server1，serever2而言，都统计出集群中已经有两台机器接手里(2，0)的投票信息，此时便认为			   已经选出了leader
            5、改变服务器状态。一旦确定leader，每个服务器就会更新自己的状态，如果是follower，那么就会变更为			   following，如果为leader就会变更为leading


        服务器运行时期的leader选举
            在zookeeper运行期间，leader与非leader的服务器将各司其职，即便当有非leader的服务器down机或者有新机器加入，此时也不会影响
            leader，但是一旦leader挂了，那么整个集群将会暂停对外的服务，进入新一轮的leader选举，其过程进而启动时期的leader选举基本一致
            1、变更状态。leader挂后，余下的服务器都会将自己的 服务器的状态变更为looking，然后开始重新选举
            2、每个server会发出一个投票，在运行期间，每个服务器上的zxid可能不同，剩下的与启动过程相同
    
        zookeeper观察者角色
            观察者的设计是希望能动态扩展zookeeper集群又不会降低写性能。
            虽然通过让客户端直接连接到集群的投票成员，ZooKeeper也表现得非常好，但是这种架构使得很难扩展到有大量的客户端情况。
            问题是，随着我们添加更多投票成员，写入性能也会随着下降。这是因为写操作需要（通常）需要集群中至少一半的节点投票达
            成一致，因此随着更多投票者的加入，投票的成本会显著增加。
            这里引入一种新zookeeper节点类型，叫做观察者，观察者的引入帮助解决了上面的问题同时大大增加了zookeeper的动态扩展
            能力。观察者不参与投票，只听取投票结果。除了这个简单的区别，Observers的功能与Followers完全相同 - 客户端可以连
            接到它们并向它们发送读写请求。Observer会像follower一样将消息转发给leader，但是Observer只会听取投票结果，不参
            与投票。由于这点，我们可以增加任意数量的Observer，同时不会影响我们集群的性能。
            Observer还有其它优点。因为他们不投票，所以他们不是ZooKeeper集群的重要组成部分。 因此，它们可以失败，或者与集
            群断开连接，而不会损害ZooKeeper服务的可用性。对用户的好处是Observer相比Follower来说更能通过不太可靠的网络链接
            进行连接。实际上，Observers可用于与另一个数据中心的ZooKeeper服务器通信。Observers的客户端可以快速读取，因为
            所有读取都在本地提供，并且写入消耗最小的网络流量，因为在没有投票协议的情况下所需的消息数量较少
            observer角色特点
                1、不参与集群中的leader选举
                2、不参与集群中写数据时的ack反馈(接收到leader发出事务提议后，不需要反馈给leader)
                为了方便使用observer角色，在任何想变成observer角色的配置文件中加入如下配置
                peerType=observer
                并在所有server配置文件中，将配置成observer模式的那台server的那行配置后面追加observer，例如
                server.3=192.168.1.5:3389:observer
    
        zookeeperApi连接集群
            集群中的服务器地址逗号分隔
            ZooKeeper zookeeper = new ZooKeeper("192.168.195.1:2181,192.168.195.1:2182,192.168.195.1:2183", 50000,watcher );


    zookeeper开源客户端curator介绍
        原生javaapi不足点
        1、连接对象异步创建，需要开发人员自行编码等待
        2、连接没有超时自动重连机制
        3、watcher一次注册生效一次
        4、不支持递归创建树形节点
    
        curator特点
        1、解决session会话超时重连
        2、watcher反复注册
        3、简化开发api
        4、遵顼fluent风格的api
        5、提供了分布式锁服务、共享计数器、缓存机制等机制
    
            引入依赖
                <dependency>
                    <groupId>org.apache.curator</groupId>
                    <artifactId>curator-framework</artifactId>
                    <version>2.11.0</version>
                </dependency>
                <dependency>
                    <groupId>org.apache.curator</groupId>
                    <artifactId>curator-recipes</artifactId>
                    <version>2.11.0</version>
                </dependency>
    
    创建连接对象
        //创建连接对象（fluent风格）
        CuratorFramework client = CuratorFrameworkFactory.builder()
                //ip地址和端口号
                .connectString("192.168.195.1:2181")
                //客户端和服务器之间的超时时间
                .sessionTimeoutMs(5000)
                //会话超时后的处置策略
                //重连机制
                .retryPolicy(new RetryOneTime(3000))
                //命名空间，父节点
                .namespace("create")
                //构建链接对象
                .build();
        //打开连接
        System.out.println(client.isStarted());
    
        //关闭连接
        client.close();
    
    curator连接对象的重连机制
        1、//curator连接对象的重连策略
                  //1、3秒后重连一次,只重连一次
                  RetryPolicy retryPolicy = new RetryOneTime(3000);
    
                  //2、每3秒重连一次，重连3次
                  retryPolicy = new RetryNTimes(3,3000);
    
                  //3、每3秒重连一次，总等待时间超过10秒后停止重连
                  retryPolicy = new RetryUntilElapsed(10000,3000);
    
                  //4、重连3次，但是间隔时间会随着重连的次数变长
                  //里面有一个算法用来计算间隔时间的
                  //baseSleepTimeMs * Math.max(1,random.nextInt(1 << (retryCount + 1)))
                  retryPolicy = new ExponentialBackoffRetry(1000,3);


    创建节点
        1、创建节点
        //        client.create()
        //                .withMode(CreateMode.PERSISTENT)
        //                .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE)
        //                //相当于创建/create3/node1,可选
        //                .forPath("/node1","node1".getBytes());
    
                //2、递归创建节点树
        //        client.create()
        //                //父节点如果没有的话会自动创建
        //                .creatingParentsIfNeeded()
        //                .withMode(CreateMode.PERSISTENT)
        //                .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE)
        //                //相当于创建/create3/node1,可选
        //                .forPath("/node2/node3/node4","node4".getBytes());
    
                //3、异步方式创建节点
                client.create()
                        //父节点如果没有的话会自动创建
                        .creatingParentsIfNeeded()
                        .withMode(CreateMode.PERSISTENT)
                        .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE)
                        .inBackground(new BackgroundCallback() {
                            @Override
                            public void processResult(CuratorFramework client, CuratorEvent event) throws Exception {
                                System.out.println("我是异步。。。。。。");
                                System.out.println(event.getType());
                            }
                        })
                        //相当于创建/create3/node1,可选
                        .forPath("/node5/node5","node5".getBytes());
                System.out.println("我直接出来了！");
    
    监听机制
        curator包含了两种wathcer(cache)来监听节点的变化(可以监听多次)
        NodeCache：只是监听某一个特定的节点，监听节点的新增和修改
        PathChildrenCache：来监控一个节点的子节点，当一个子节点增加，更新，删除时，pathCache会改变他的状态，会包含最新
                            的子节点，子节点的状态和数据
    
        CuratorCache curatorCache = CuratorCache.builder(client, "/create").build();
    
                CuratorCacheListener listener = CuratorCacheListener
                        .builder()
                        .forNodeCache(new NodeCacheListener(){
    
                            @Override
                            public void nodeChanged() throws Exception {
                                System.out.println("/create");
                            }
                        })
                        .build();
                curatorCache.listenable().addListener(listener);
                //启用监听器
                curatorCache.start();
                Thread.sleep(100000);
                curatorCache.close();
    
    事务
        这里的事务和数据库事务一样，一组操作遵循原子性
        client
            .inTransaction()
            .create().forPath("/node0","node0".getBytes())
            .and()
            .setData().forPath("/node1","node1".getBytes())
            .and()
            .commit();
    
    分布式锁
        interProcessMutex:分布式可重入排他锁
                InterProcessLock lock1 = new InterProcessMutex(client,"/lock1");
                System.out.println("等待获取锁对象");
                lock1.acquire();
                for (int i = 0; i < 10; i++) {
                    Thread.sleep(1000);
                    System.out.println(i);
                }
                lock1.release();
                System.out.println("等待释放锁");
    
        interProcessReadWriteLock：分布式读写锁
            InterProcessReadWriteLock lock2 = new InterProcessReadWriteLock(client,"/lock1");
            InterProcessMutex readLock = lock2.readLock();
    
            System.out.println("等待获取锁对象");
            readLock.acquire();
            for (int i = 0; i < 10; i++) {
                Thread.sleep(1000);
                System.out.println(i);
            }
            readLock.release();
            System.out.println("等待释放锁");



            InterProcessReadWriteLock lock3 = new InterProcessReadWriteLock(client,"/lock1");
            InterProcessMutex writeLock = lock3.writeLock();
    
            System.out.println("等待获取锁对象");
            writeLock.acquire();
            for (int i = 0; i < 10; i++) {
                Thread.sleep(1000);
                System.out.println(i);
            }
            writeLock.release();
            System.out.println("等待释放锁");
